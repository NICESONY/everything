{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75f9f36",
   "metadata": {},
   "source": [
    "<h3> 1. 필요한 라이브러리 모두 불러오기 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0c3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65143c4",
   "metadata": {},
   "source": [
    "<h3> 2. 데이터를 살펴보기 위한 함수 설정하기 </h3>\n",
    "<p> 저같은 경우에는 EDA를 할 때 기본적인 틀이 존재해서 함수로 설정하였습니다. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55a90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info(df : pd.DataFrame) -> None:\n",
    "    print('column의 개수 : ', len(df.columns))\n",
    "    print('데이터의 개수 : ', len(df))\n",
    "    print('데이터의 shape : ', df.shape)\n",
    "    print('categorical 변수의 개수 : ', len(df.columns[df.dtypes == 'object']))\n",
    "    print('categorical 컬럼 : ', df.columns[df.dtypes == 'object'])\n",
    "    print('numerical 변수의 개수 : ', len(df.columns[df.dtypes != 'object']))\n",
    "    print('numerical 컬럼 : ', df.columns[df.dtypes != 'object'])\n",
    "    print('결측치 개수 : ', df.isnull().sum().sum())\n",
    "    print('====================================================================')\n",
    "    print('컬럼 이름 : ', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87462b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_columns(df : pd.DataFrame, columns : str, target : str) -> None:\n",
    "    print('컬럼명 : ', columns)\n",
    "    print('컬럼 분포 ', df[columns].value_counts(normalize = True).sort_values(ascending = True))\n",
    "    print('라벨 별 target 비율 : ', df.groupby(columns)[target].mean())\n",
    "\n",
    "# 분류 문제에서만 사용\n",
    "def search_target_ratio(df : pd.DataFrame, columns : str, target : str) -> None:\n",
    "    return pd.crosstab(df[columns], df[target], margins = True, normalize = 'index').style.background_gradient(cmap = 'summer_r')\n",
    "\n",
    "\n",
    "# 연속형 변수들에 대한 분포 확인하기\n",
    "def numerical_plot(df : pd.DataFrame, columns : list, nrows : int, ncols : int, row_size : int, col_size : int) -> None:\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize = (row_size, col_size))\n",
    "    count = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            sns.distplot(x = df[columns[count]], ax = axes[i][j])\n",
    "            axes[i][j].set_title(columns[count] + 'column distribution')\n",
    "            axes[i][j].set_xlabel(columns[count])\n",
    "            count += 1\n",
    "\n",
    "# 상관계수 확인하기\n",
    "def correlation_matrix(df : pd.DataFrame, numerical_columns : list, figsize : tuple) -> None:\n",
    "    colormap = plt.cm.PuBu\n",
    "    plt.title('Pearson Corrleation of data')\n",
    "    plt.figure(figsize = figsize)\n",
    "    if len(numerical_columns) <= 20:\n",
    "        sns.heatmap(df[numerical_columns].astype(float).corr(), linewidths = 0.1, vmax = 1.0,\n",
    "            square = True, cmap = colormap, linecolor = \"white\", annot = True, annot_kws = {\"size\" : 16})\n",
    "    else:\n",
    "        sns.heatmap(df[numerical_columns].astype(float).corr(), linewidths = 0.1, vmax = 1.0, square = True, cmap = colormap)\n",
    "\n",
    "def describe_matrix(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.describe()\n",
    "\n",
    "# 범주형 변수에 대한 countplot\n",
    "def column_bar_plot(df : pd.DataFrame, columns : str) -> None:\n",
    "    sns.countplot(x = df[columns])\n",
    "    \n",
    "# 이상치 처리\n",
    "def outlier_to_normal(x, lower_bound, upper_bound):\n",
    "    if x < lower_bound:\n",
    "        return lower_bound\n",
    "    elif x > upper_bound:\n",
    "        return upper_bound\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# 이상치 처리 -> Q3 이상 값에 대해서는 Q3 값으로 처리\n",
    "def outlier_transform(train_df : pd.DataFrame, test_df : pd.DataFrame, \n",
    "                      columns : list) -> (pd.DataFrame, pd.DataFrame):\n",
    "    for column in columns:\n",
    "        q1 = np.percentile(train_df[column], 25)\n",
    "        q3 = np.percentile(train_df[column], 75)\n",
    "        lower_bound = q1 - 1.5 * (q3 - q1)\n",
    "        upper_bound = q3 + 1.5 * (q3 - q1)\n",
    "        train_df[column] = train_df[column].apply(lambda x : \n",
    "                                        outlier_to_normal(x, lower_bound, upper_bound))\n",
    "        test_df[column] = test_df[column].apply(lambda x : \n",
    "                                                outlier_to_normal(x, lower_bound, upper_bound))\n",
    "    return (train_df, test_df)\n",
    "    \n",
    "# 범주형 변수 => 라벨인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def categorical_column_preprocessing(train_df : pd.DataFrame, test_df : pd.DataFrame, columns : list) -> (pd.DataFrame, pd.DataFrame):\n",
    "    train_data = train_df.copy()\n",
    "    test_data = test_df.copy()\n",
    "    for column in columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_data[column])\n",
    "        print(column + ' label encoder classes', le.classes_)\n",
    "        train_data[column] = le.transform(train_data[column])\n",
    "        test_data[column] = le.transform(test_data[column])\n",
    "\n",
    "    return (train_data, test_data)\n",
    "\n",
    "# 표준화\n",
    "def standard_scaler(train_df : pd.DataFrame, test_df : pd.DataFrame, categorical_columns, numeric_columns : list) -> (pd.DataFrame, pd.DataFrame):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df[numeric_columns])\n",
    "    x_scaled = pd.DataFrame(scaler.transform(train_df[numeric_columns]), columns = numeric_columns)\n",
    "    x_test_scaled = pd.DataFrame(scaler.transform(test_df[numeric_columns]), columns = numeric_columns)\n",
    "\n",
    "    train_data = pd.concat([train_df[categorical_columns], x_scaled], axis = 1)\n",
    "    test_data = pd.concat([test_df[categorical_columns], x_test_scaled], axis = 1)\n",
    "    return (train_data, test_data)\n",
    "\n",
    "# 로그화\n",
    "def log_transform(train_df : pd.DataFrame, test_df : pd.DataFrame, categorical_columns, numeric_columns : list) -> (pd.DataFrame, pd.DataFrame):\n",
    "\n",
    "    train_df[numeric_columns] = np.log1p(train_df[numeric_columns])\n",
    "    test_df[numeric_columns] = np.log1p(test_df[numeric_columns])\n",
    "    return (train_df, test_df)\n",
    "\n",
    "# 정규화(Minmax-scaler)\n",
    "def minmax_scaler(train_df : pd.DataFrame, test_df : pd.DataFrame, categorical_columns, numeric_columns : list) -> (pd.DataFrame, pd.DataFrame):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_df[numeric_columns])\n",
    "    x_scaled = pd.DataFrame(scaler.transform(train_df[numeric_columns]), columns = numeric_columns)\n",
    "    x_test_scaled = pd.DataFrame(scaler.transform(test_df[numeric_columns]), columns = numeric_columns)\n",
    "\n",
    "    train_data = pd.concat([train_df[categorical_columns], x_scaled], axis = 1)\n",
    "    test_data = pd.concat([test_df[categorical_columns], x_test_scaled], axis = 1)\n",
    "    return (train_data, test_data)\n",
    "\n",
    "# 학습 / 테스트 분리하기\n",
    "def train_test(X : pd.DataFrame, y : pd.DataFrame, test_size : float, random_state = 42) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = test_size, random_state = 42, stratify = y)\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a0118",
   "metadata": {},
   "source": [
    "<h3> 3. 데이터 불러오기 및 데이터 전처리 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da91af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "train_df = pd.read_csv('train.csv').drop('ID', axis = 1).drop_duplicates().reset_index(drop = True)\n",
    "test_df = pd.read_csv('test.csv').drop('ID', axis = 1)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "target = 'monthlyRent(us_dollar)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552a96a",
   "metadata": {},
   "source": [
    "<p> suburbName에 너무 많아서 라벨인코딩시에 부정적 영향(스케일이 큰 것을 크게 측정)을 줄 수 있어서 대체하였습니다. 또한, 일부분은 1개만 존재하거나 수가 적었기 때문에 다른 것을 통합하였습니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a90144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['suburbName'] == 'West Delhi'), 'suburbName'] = 'Delhi West'\n",
    "train_df.loc[train_df['suburbName'] == 'North Delhi', 'suburbName'] = 'Delhi North'\n",
    "train_df.loc[train_df['suburbName'] == 'Dwarka', 'suburbName'] = 'North West Delhi'\n",
    "train_df.loc[train_df['suburbName'] == 'Rohini', 'suburbName'] = 'South West Delhi'\n",
    "train_df.loc[train_df['propertyType'] == 'Villa', 'propertyType'] = 'Independent Floor'\n",
    "\n",
    "test_df.loc[(test_df['suburbName'] == 'West Delhi'), 'suburbName'] = 'Delhi West'\n",
    "test_df.loc[test_df['suburbName'] == 'North Delhi', 'suburbName'] = 'Delhi North'\n",
    "test_df.loc[test_df['suburbName'] == 'Dwarka', 'suburbName'] = 'North West Delhi'\n",
    "test_df.loc[test_df['suburbName'] == 'Rohini', 'suburbName'] = 'South West Delhi'\n",
    "test_df.loc[test_df['propertyType'] == 'Villa', 'propertyType'] = 'Independent Floor'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1648f5c",
   "metadata": {},
   "source": [
    "<p> 위도와 경도에 대해서 군집화를 실행하고 각 군집 별로 라벨링을 붙였습니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633ca5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "x = train_df.loc[:, ['latitude', 'longitude']]\n",
    "x_test = test_df.loc[:, ['latitude', 'longitude']]\n",
    "kmeans = KMeans(4, init = 'k-means++',  n_init= 20)\n",
    "kmeans.fit(x)\n",
    "\n",
    "train_clusters = kmeans.predict(x)\n",
    "test_clusters = kmeans.predict(x_test)\n",
    "\n",
    "train_df['cluster'] = train_clusters\n",
    "test_df['cluster'] = test_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38eb205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76.6, 77.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_df['latitude'], train_df['longitude'],\n",
    "           c = train_df['cluster'], cmap = 'rainbow')\n",
    "plt.xlim([28.2, 28.8])\n",
    "plt.ylim([76.6, 77.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc07dce",
   "metadata": {},
   "source": [
    "<p> 범주형 변수 처리, 이상치 처리, 표준화, 로그화를 진행하였습니다. 실제 학습시킨 데이터는 라벨인코딩/이상치/로그화 입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f694b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propertyType label encoder classes ['Apartment' 'Independent Floor' 'Independent House']\n",
      "suburbName label encoder classes ['Delhi Central' 'Delhi East' 'Delhi North' 'Delhi South' 'Delhi West'\n",
      " 'North West Delhi' 'Other' 'South West Delhi']\n"
     ]
    }
   ],
   "source": [
    "train_df_encoder, test_df_encoder = categorical_column_preprocessing(train_df, test_df, \n",
    "                                                     ['propertyType', 'suburbName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42afc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['bedrooms', 'distanceMetro(km)',\n",
    "                    'distanceAirport(km)', 'distanceHospital(km)',\n",
    "                    'distanceRailway(km)', 'area(square_meters)', 'latitude', 'longitude']\n",
    "outlier_train, outlier_test = outlier_transform(train_df_encoder, test_df_encoder, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "498d317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['propertyType', 'bedrooms', 'latitude', 'longitude', 'suburbName',\n",
       "       'distanceMetro(km)', 'distanceAirport(km)', 'distanceHospital(km)',\n",
       "       'distanceRailway(km)', 'area(square_meters)', 'monthlyRent(us_dollar)',\n",
       "       'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2351305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['bedrooms', 'distanceMetro(km)',\n",
    "                    'distanceAirport(km)', 'distanceHospital(km)',\n",
    "                    'distanceRailway(km)', 'area(square_meters)', 'latitude', 'longitude']\n",
    "categorical_columns = ['propertyType', 'suburbName',  target]\n",
    "standard_train, standard_test = standard_scaler(outlier_train, outlier_test, categorical_columns[:-1], \n",
    "                                   numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd6d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['bedrooms', 'distanceMetro(km)',\n",
    "                    'distanceAirport(km)', 'distanceHospital(km)',\n",
    "                    'distanceRailway(km)', 'area(square_meters)', 'latitude', 'longitude']\n",
    "categorical_columns = ['propertyType', 'suburbName', target]\n",
    "log_train, log_test = log_transform(outlier_train, outlier_test, categorical_columns[:-1], \n",
    "                                   numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a96769",
   "metadata": {},
   "source": [
    "<h3> 4. 모델 구축 -- 베이스라인 모델 측정 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed1958a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================== 베이스 라인 모델 평가 ==========================================\n",
      "모델명 : ExtraTreesRegressor   평균 RMSE : 0.2585, 표준편차 : 0.0111\n",
      "모델명 : LinearRegression   평균 RMSE : 0.3127, 표준편차 : 0.0134\n",
      "모델명 : Ridge   평균 RMSE : 0.3205, 표준편차 : 0.0133\n",
      "모델명 : RandomForestRegressor   평균 RMSE : 0.2575, 표준편차 : 0.0144\n",
      "모델명 : GradientBoostingRegressor   평균 RMSE : 0.2686, 표준편차 : 0.0107\n",
      "모델명 : XGBRegressor   평균 RMSE : 0.2536, 표준편차 : 0.0119\n",
      "모델명 : LGBMRegressor   평균 RMSE : 0.2513, 표준편차 : 0.0145\n",
      "모델명 : AdaBoostRegressor   평균 RMSE : 0.3506, 표준편차 : 0.0090\n",
      "모델명 : CatBoostRegressor   평균 RMSE : 0.2459, 표준편차 : 0.0116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import AdaBoostRegressor, VotingRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = log_train.drop(target, axis = 1)\n",
    "y = np.log1p(log_train[target])\n",
    "ex_rlf = ExtraTreesRegressor(random_state = 42)\n",
    "lr_rlf = LinearRegression()\n",
    "rg_rlf = Ridge()\n",
    "rf_rlf = RandomForestRegressor(random_state = 42)\n",
    "gb_rlf = GradientBoostingRegressor(random_state = 42)\n",
    "xgb_rlf = xgb.XGBRegressor(random_state = 42)\n",
    "lgb_rlf = lgb.LGBMRegressor(random_state = 42)\n",
    "ada_rlf = AdaBoostRegressor(random_state = 42)\n",
    "cat_rlf = CatBoostRegressor(random_state = 42, loss_function = 'RMSE', verbose = 0)\n",
    "\n",
    "models = [ex_rlf, lr_rlf, rg_rlf, rf_rlf, gb_rlf, xgb_rlf, lgb_rlf,\n",
    "         ada_rlf, cat_rlf]\n",
    "\n",
    "print('====================================== 베이스 라인 모델 평가 ==========================================')\n",
    "for model in models:\n",
    "    cv_score = cross_val_score(model, X, y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "    rmse_score = np.sqrt(-1 * cv_score)\n",
    "    avg_rmse = rmse_score.mean()\n",
    "    avg_std = rmse_score.std()\n",
    "    print('모델명 : {}  '.format(model.__class__.__name__), end = ' ')\n",
    "    print('평균 RMSE : {0:.4f}, 표준편차 : {1:.4f}'.format(avg_rmse, avg_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d436ac",
   "metadata": {},
   "source": [
    "<h3> 5. 하이퍼 파라미터 튜닝 -- Optuna로 진행 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3bb9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a916a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "def tune_model(model_type, X, Y, n_trials=500, cv=10):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    \n",
    "    if model_type=='lgb':\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 300, 824, step=1, log=True), \n",
    "                'max_depth': trial.suggest_int('max_depth', 6, 20, step=1, log=False), \n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True), \n",
    "                'n_estimators': trial.suggest_int('n_estimators', 1500, 3000, step=1, log=True), \n",
    "                'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False), \n",
    "                'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), \n",
    "                'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "                'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 1.0),\n",
    "            }\n",
    "            model = lgb.LGBMRegressor(random_state = 42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "            rmse_score = np.sqrt(-1 * score)\n",
    "            avg_rmse = rmse_score.mean()\n",
    "            avg_std = rmse_score.std()\n",
    "            print(avg_rmse, avg_std)\n",
    "            return avg_rmse\n",
    "    \n",
    "\n",
    "    elif model_type=='cat':\n",
    "         def objective(trial):\n",
    "            params={}\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 500)\n",
    "            params['learning_rate'] = trial.suggest_loguniform('learning_rate', 0.03, 0.5)\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 6, 12)\n",
    "            params['reg_lambda'] = trial.suggest_loguniform('reg_lambda', 1e-4, 30)\n",
    "            params['random_strength'] = trial.suggest_uniform('random_strength', 0.1, 30)\n",
    "            params['bootstrap_type'] = trial.suggest_categorical('bootstrap_type', ['Bayesian'])\n",
    "            params['bagging_temperature'] = trial.suggest_uniform('bagging_temperature', 0, 30)\n",
    "             \n",
    "            model = CatBoostRegressor(random_state = 42, verbose = 0, **params)\n",
    "            score = cross_val_score(model, X, Y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "            rmse_score = np.sqrt(-1 * score)\n",
    "            avg_rmse = rmse_score.mean()\n",
    "            avg_std = rmse_score.std()\n",
    "            print(avg_rmse, avg_std)\n",
    "            return avg_rmse\n",
    "\n",
    "        \n",
    "    elif model_type=='rf':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1000, 3000)\n",
    "            max_depth = trial.suggest_int('max_depth', 6, 20)\n",
    "            max_features = trial.suggest_uniform('max_features', 0, 1)\n",
    "            max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 250)\n",
    "            criterion = trial.suggest_categorical('criterion', ['friedman_mse','squared_error'])\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'max_features' : max_features, \n",
    "                      'max_depth' : max_depth,\n",
    "                      'criterion' : criterion,\n",
    "                      'max_leaf_nodes' : max_leaf_nodes,\n",
    "                     }\n",
    "            model = RandomForestRegressor(random_state = 42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "            rmse_score = np.sqrt(-1 * score)\n",
    "            avg_rmse = rmse_score.mean()\n",
    "            avg_std = rmse_score.std()\n",
    "            print(avg_rmse, avg_std)\n",
    "            return avg_rmse\n",
    "        \n",
    "        \n",
    "    elif model_type=='ets':\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                \"criterion\": trial.suggest_categorical(\"criterion\", ['squared_error']),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 4,14),\n",
    "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\",2,20),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\",1, 100),\n",
    "            }\n",
    "\n",
    "            model = ExtraTreesRegressor(random_state = 42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "            rmse_score = np.sqrt(-1 * score)\n",
    "            avg_rmse = rmse_score.mean()\n",
    "            avg_std = rmse_score.std()\n",
    "            print(avg_rmse, avg_std)\n",
    "            return avg_rmse\n",
    "\n",
    "\n",
    "    elif model_type == 'xgb':\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 16),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 0.05, 0.99),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 1000, 10000, step=100),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 1, log= True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 1, log= True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0, step = 0.05),     \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0, log=True),\n",
    "            }\n",
    "\n",
    "            model = xgb.XGBRegressor(random_state = 42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "            rmse_score = np.sqrt(-1 * score)\n",
    "            avg_rmse = rmse_score.mean()\n",
    "            avg_std = rmse_score.std()\n",
    "            print(avg_rmse, avg_std)\n",
    "            return avg_rmse\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    study=optuna.create_study(direction='minimize', \n",
    "                              sampler = sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(f\"Model : {model_type}, Best Score : {study.best_value}, Best Params : {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2da8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves': 336, 'max_depth': 6, 'learning_rate': 0.016397540368664684, 'n_estimators': 1663, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8814135267862333, 'colsample_bytree': 0.7687915082406303, 'reg_alpha': 0.1505001351493313, 'reg_lambda': 0.10096359200658506}\n",
    "ex_params = {'n_estimators': 417, 'criterion': 'squared_error', 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 1}\n",
    "rf_params = {'n_estimators': 1371, 'max_depth': 15, 'max_features': 0.3152787366490212, 'max_leaf_nodes': 249, 'criterion': 'squared_error'}\n",
    "cat_params = {'n_estimators': 457, 'learning_rate': 0.04877783049463647, 'max_depth': 9, 'reg_lambda': 0.6445607071063436, 'random_strength': 1.1307597759505224, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.1347780701107058}\n",
    "\n",
    "cat_rlf = CatBoostRegressor(**cat_params, random_state = 42, verbose = 0)\n",
    "lgb_rlf = lgb.LGBMRegressor(**lgb_params, random_state = 42)\n",
    "ex_rlf = ExtraTreesRegressor(**ex_params, random_state = 42)\n",
    "rf_rlf = RandomForestRegressor(**rf_params, random_state = 42)\n",
    "xgb_rlf = xgb.XGBRegressor(random_state = 42)\n",
    "cat_rlf.fit(X, y)\n",
    "lgb_rlf.fit(X, y)\n",
    "ex_rlf.fit(X, y)\n",
    "rf_rlf.fit(X, y)\n",
    "xgb_rlf.fit(X, y)\n",
    "\n",
    "cat_pred = cat_rlf.predict(log_test)\n",
    "lgb_pred = lgb_rlf.predict(log_test)\n",
    "ex_pred = ex_rlf.predict(log_test)\n",
    "rf_pred = rf_rlf.predict(log_test)\n",
    "xgb_pred = xgb_rlf.predict(log_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e056b",
   "metadata": {},
   "source": [
    "<p> 최종 제출 : catboost, lightgbm, extratree, randomforest, xgboost </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dc52c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_pred = np.expm1(cat_pred) * 0.3 + np.expm1(lgb_pred) * 0.25 + np.expm1(ex_pred) * 0.3 + np.expm1(rf_pred) * 0.05 + np.expm1(xgb_pred) * 0.1\n",
    "submission_df[target] = vt_pred\n",
    "submission_df.to_csv('log ensemble finally_1226_Version2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
