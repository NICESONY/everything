{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.42099</td>\n",
       "      <td>0.39479</td>\n",
       "      <td>0.42310</td>\n",
       "      <td>0.40580</td>\n",
       "      <td>0.55107</td>\n",
       "      <td>0.41532</td>\n",
       "      <td>0.10631</td>\n",
       "      <td>0.20542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>0.40409</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46583</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.34401</td>\n",
       "      <td>0.22868</td>\n",
       "      <td>0.26533</td>\n",
       "      <td>0.16498</td>\n",
       "      <td>0.60467</td>\n",
       "      <td>0.65628</td>\n",
       "      <td>0.58338</td>\n",
       "      <td>0.07245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18003</td>\n",
       "      <td>0.20223</td>\n",
       "      <td>0.17768</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.62743</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>0.11400</td>\n",
       "      <td>0.14434</td>\n",
       "      <td>0.09053</td>\n",
       "      <td>43.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>4</td>\n",
       "      <td>0.34437</td>\n",
       "      <td>0.25134</td>\n",
       "      <td>0.26510</td>\n",
       "      <td>0.16350</td>\n",
       "      <td>0.60353</td>\n",
       "      <td>0.45025</td>\n",
       "      <td>0.59097</td>\n",
       "      <td>0.18672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21317</td>\n",
       "      <td>0.20223</td>\n",
       "      <td>0.20660</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.50931</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>0.16327</td>\n",
       "      <td>0.14434</td>\n",
       "      <td>0.14951</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0  TRAIN_00000                   3           0.42099               0.39479   \n",
       "1  TRAIN_00001                   4           0.34401               0.22868   \n",
       "2  TRAIN_00002                   4           0.34437               0.25134   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0            0.42310                0.40580              0.55107   \n",
       "1            0.26533                0.16498              0.60467   \n",
       "2            0.26510                0.16350              0.60353   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  ...  \\\n",
       "0                  0.41532            0.10631                0.20542  ...   \n",
       "1                  0.65628            0.58338                0.07245  ...   \n",
       "2                  0.45025            0.59097                0.18672  ...   \n",
       "\n",
       "   wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  entropy_Valence  \\\n",
       "0           0.83333        0.83333            0.83333           0.5129   \n",
       "1           0.18003        0.20223            0.17768           0.6391   \n",
       "2           0.21317        0.20223            0.20660           0.6391   \n",
       "\n",
       "   wtd_entropy_Valence  range_Valence  wtd_range_Valence  std_Valence  \\\n",
       "0              0.40409        0.00000            0.46583      0.00000   \n",
       "1              0.62743        0.16667            0.11400      0.14434   \n",
       "2              0.50931        0.16667            0.16327      0.14434   \n",
       "\n",
       "   wtd_std_Valence  critical_temp  \n",
       "0          0.00000           5.69  \n",
       "1          0.09053          43.60  \n",
       "2          0.14951          39.00  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12759 entries, 0 to 12758\n",
      "Data columns (total 83 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   ID                               12759 non-null  object \n",
      " 1   number_of_elements               12759 non-null  int64  \n",
      " 2   mean_atomic_mass                 12759 non-null  float64\n",
      " 3   wtd_mean_atomic_mass             12759 non-null  float64\n",
      " 4   gmean_atomic_mass                12759 non-null  float64\n",
      " 5   wtd_gmean_atomic_mass            12759 non-null  float64\n",
      " 6   entropy_atomic_mass              12759 non-null  float64\n",
      " 7   wtd_entropy_atomic_mass          12759 non-null  float64\n",
      " 8   range_atomic_mass                12759 non-null  float64\n",
      " 9   wtd_range_atomic_mass            12759 non-null  float64\n",
      " 10  std_atomic_mass                  12759 non-null  float64\n",
      " 11  wtd_std_atomic_mass              12759 non-null  float64\n",
      " 12  mean_fie                         12759 non-null  float64\n",
      " 13  wtd_mean_fie                     12759 non-null  float64\n",
      " 14  gmean_fie                        12759 non-null  float64\n",
      " 15  wtd_gmean_fie                    12759 non-null  float64\n",
      " 16  entropy_fie                      12759 non-null  float64\n",
      " 17  wtd_entropy_fie                  12759 non-null  float64\n",
      " 18  range_fie                        12759 non-null  float64\n",
      " 19  wtd_range_fie                    12759 non-null  float64\n",
      " 20  std_fie                          12759 non-null  float64\n",
      " 21  wtd_std_fie                      12759 non-null  float64\n",
      " 22  mean_atomic_radius               12759 non-null  float64\n",
      " 23  wtd_mean_atomic_radius           12759 non-null  float64\n",
      " 24  gmean_atomic_radius              12759 non-null  float64\n",
      " 25  wtd_gmean_atomic_radius          12759 non-null  float64\n",
      " 26  entropy_atomic_radius            12759 non-null  float64\n",
      " 27  wtd_entropy_atomic_radius        12759 non-null  float64\n",
      " 28  range_atomic_radius              12759 non-null  float64\n",
      " 29  wtd_range_atomic_radius          12759 non-null  float64\n",
      " 30  std_atomic_radius                12759 non-null  float64\n",
      " 31  wtd_std_atomic_radius            12759 non-null  float64\n",
      " 32  mean_Density                     12759 non-null  float64\n",
      " 33  wtd_mean_Density                 12759 non-null  float64\n",
      " 34  gmean_Density                    12759 non-null  float64\n",
      " 35  wtd_gmean_Density                12759 non-null  float64\n",
      " 36  entropy_Density                  12759 non-null  float64\n",
      " 37  wtd_entropy_Density              12759 non-null  float64\n",
      " 38  range_Density                    12759 non-null  float64\n",
      " 39  wtd_range_Density                12759 non-null  float64\n",
      " 40  std_Density                      12759 non-null  float64\n",
      " 41  wtd_std_Density                  12759 non-null  float64\n",
      " 42  mean_ElectronAffinity            12759 non-null  float64\n",
      " 43  wtd_mean_ElectronAffinity        12759 non-null  float64\n",
      " 44  gmean_ElectronAffinity           12759 non-null  float64\n",
      " 45  wtd_gmean_ElectronAffinity       12759 non-null  float64\n",
      " 46  entropy_ElectronAffinity         12759 non-null  float64\n",
      " 47  wtd_entropy_ElectronAffinity     12759 non-null  float64\n",
      " 48  range_ElectronAffinity           12759 non-null  float64\n",
      " 49  wtd_range_ElectronAffinity       12759 non-null  float64\n",
      " 50  std_ElectronAffinity             12759 non-null  float64\n",
      " 51  wtd_std_ElectronAffinity         12759 non-null  float64\n",
      " 52  mean_FusionHeat                  12759 non-null  float64\n",
      " 53  wtd_mean_FusionHeat              12759 non-null  float64\n",
      " 54  gmean_FusionHeat                 12759 non-null  float64\n",
      " 55  wtd_gmean_FusionHeat             12759 non-null  float64\n",
      " 56  entropy_FusionHeat               12759 non-null  float64\n",
      " 57  wtd_entropy_FusionHeat           12759 non-null  float64\n",
      " 58  range_FusionHeat                 12759 non-null  float64\n",
      " 59  wtd_range_FusionHeat             12759 non-null  float64\n",
      " 60  std_FusionHeat                   12759 non-null  float64\n",
      " 61  wtd_std_FusionHeat               12759 non-null  float64\n",
      " 62  mean_ThermalConductivity         12759 non-null  float64\n",
      " 63  wtd_mean_ThermalConductivity     12759 non-null  float64\n",
      " 64  gmean_ThermalConductivity        12759 non-null  float64\n",
      " 65  wtd_gmean_ThermalConductivity    12759 non-null  float64\n",
      " 66  entropy_ThermalConductivity      12759 non-null  float64\n",
      " 67  wtd_entropy_ThermalConductivity  12759 non-null  float64\n",
      " 68  range_ThermalConductivity        12759 non-null  float64\n",
      " 69  wtd_range_ThermalConductivity    12759 non-null  float64\n",
      " 70  std_ThermalConductivity          12759 non-null  float64\n",
      " 71  wtd_std_ThermalConductivity      12759 non-null  float64\n",
      " 72  mean_Valence                     12759 non-null  float64\n",
      " 73  wtd_mean_Valence                 12759 non-null  float64\n",
      " 74  gmean_Valence                    12759 non-null  float64\n",
      " 75  wtd_gmean_Valence                12759 non-null  float64\n",
      " 76  entropy_Valence                  12759 non-null  float64\n",
      " 77  wtd_entropy_Valence              12759 non-null  float64\n",
      " 78  range_Valence                    12759 non-null  float64\n",
      " 79  wtd_range_Valence                12759 non-null  float64\n",
      " 80  std_Valence                      12759 non-null  float64\n",
      " 81  wtd_std_Valence                  12759 non-null  float64\n",
      " 82  critical_temp                    12759 non-null  float64\n",
      "dtypes: float64(81), int64(1), object(1)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.00000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "      <td>12759.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.116388</td>\n",
       "      <td>0.399213</td>\n",
       "      <td>0.328101</td>\n",
       "      <td>0.323766</td>\n",
       "      <td>0.272710</td>\n",
       "      <td>0.58757</td>\n",
       "      <td>0.543765</td>\n",
       "      <td>0.556640</td>\n",
       "      <td>0.161431</td>\n",
       "      <td>0.440387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358173</td>\n",
       "      <td>0.341746</td>\n",
       "      <td>0.342036</td>\n",
       "      <td>0.605014</td>\n",
       "      <td>0.539805</td>\n",
       "      <td>0.339865</td>\n",
       "      <td>0.212724</td>\n",
       "      <td>0.279486</td>\n",
       "      <td>0.223743</td>\n",
       "      <td>34.408760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.439978</td>\n",
       "      <td>0.146245</td>\n",
       "      <td>0.164699</td>\n",
       "      <td>0.151425</td>\n",
       "      <td>0.176247</td>\n",
       "      <td>0.18422</td>\n",
       "      <td>0.204986</td>\n",
       "      <td>0.262763</td>\n",
       "      <td>0.130694</td>\n",
       "      <td>0.198738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198380</td>\n",
       "      <td>0.173722</td>\n",
       "      <td>0.195639</td>\n",
       "      <td>0.183635</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.206801</td>\n",
       "      <td>0.140148</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.151262</td>\n",
       "      <td>34.244239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.325890</td>\n",
       "      <td>0.225855</td>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.160960</td>\n",
       "      <td>0.48852</td>\n",
       "      <td>0.395930</td>\n",
       "      <td>0.379380</td>\n",
       "      <td>0.081480</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186025</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>0.181820</td>\n",
       "      <td>0.495270</td>\n",
       "      <td>0.398760</td>\n",
       "      <td>0.166670</td>\n",
       "      <td>0.132020</td>\n",
       "      <td>0.157130</td>\n",
       "      <td>0.102715</td>\n",
       "      <td>5.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.386490</td>\n",
       "      <td>0.267310</td>\n",
       "      <td>0.299930</td>\n",
       "      <td>0.183380</td>\n",
       "      <td>0.60467</td>\n",
       "      <td>0.586090</td>\n",
       "      <td>0.590970</td>\n",
       "      <td>0.130320</td>\n",
       "      <td>0.448460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266840</td>\n",
       "      <td>0.269220</td>\n",
       "      <td>0.237730</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.597140</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.152040</td>\n",
       "      <td>0.266670</td>\n",
       "      <td>0.166530</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.463380</td>\n",
       "      <td>0.392830</td>\n",
       "      <td>0.357440</td>\n",
       "      <td>0.341705</td>\n",
       "      <td>0.72817</td>\n",
       "      <td>0.696455</td>\n",
       "      <td>0.741060</td>\n",
       "      <td>0.186770</td>\n",
       "      <td>0.587570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>0.443810</td>\n",
       "      <td>0.485810</td>\n",
       "      <td>0.741860</td>\n",
       "      <td>0.681350</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.274590</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.339930</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "count        12759.000000      12759.000000          12759.000000   \n",
       "mean             4.116388          0.399213              0.328101   \n",
       "std              1.439978          0.146245              0.164699   \n",
       "min              1.000000          0.000000              0.002560   \n",
       "25%              3.000000          0.325890              0.225855   \n",
       "50%              4.000000          0.386490              0.267310   \n",
       "75%              5.000000          0.463380              0.392830   \n",
       "max              9.000000          1.000000              1.000000   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "count       12759.000000           12759.000000          12759.00000   \n",
       "mean            0.323766               0.272710              0.58757   \n",
       "std             0.151425               0.176247              0.18422   \n",
       "min             0.001790               0.005960              0.00000   \n",
       "25%             0.260850               0.160960              0.48852   \n",
       "50%             0.299930               0.183380              0.60467   \n",
       "75%             0.357440               0.341705              0.72817   \n",
       "max             1.000000               1.000000              1.00000   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "count             12759.000000       12759.000000           12759.000000   \n",
       "mean                  0.543765           0.556640               0.161431   \n",
       "std                   0.204986           0.262763               0.130694   \n",
       "min                   0.000000           0.000000               0.000000   \n",
       "25%                   0.395930           0.379380               0.081480   \n",
       "50%                   0.586090           0.590970               0.130320   \n",
       "75%                   0.696455           0.741060               0.186770   \n",
       "max                   0.993040           1.000000               0.992170   \n",
       "\n",
       "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "count     12759.000000  ...      12759.000000   12759.000000   \n",
       "mean          0.440387  ...          0.358173       0.341746   \n",
       "std           0.198738  ...          0.198380       0.173722   \n",
       "min           0.000000  ...          0.000000       0.000000   \n",
       "25%           0.325900  ...          0.186025       0.213280   \n",
       "50%           0.448460  ...          0.266840       0.269220   \n",
       "75%           0.587570  ...          0.504170       0.443810   \n",
       "max           1.000000  ...          1.000000       1.000000   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "count       12759.000000     12759.000000         12759.000000   12759.000000   \n",
       "mean            0.342036         0.605014             0.539805       0.339865   \n",
       "std             0.195639         0.183635             0.194800       0.206801   \n",
       "min             0.000000         0.000000             0.000000       0.000000   \n",
       "25%             0.181820         0.495270             0.398760       0.166670   \n",
       "50%             0.237730         0.639100             0.597140       0.333330   \n",
       "75%             0.485810         0.741860             0.681350       0.500000   \n",
       "max             1.000000         1.000000             1.000000       1.000000   \n",
       "\n",
       "       wtd_range_Valence   std_Valence  wtd_std_Valence  critical_temp  \n",
       "count       12759.000000  12759.000000     12759.000000   12759.000000  \n",
       "mean            0.212724      0.279486         0.223743      34.408760  \n",
       "std             0.140148      0.161251         0.151262      34.244239  \n",
       "min             0.000000      0.000000         0.000000       0.000320  \n",
       "25%             0.132020      0.157130         0.102715       5.320000  \n",
       "50%             0.152040      0.266670         0.166530      20.000000  \n",
       "75%             0.274590      0.400000         0.339930      63.000000  \n",
       "max             1.000000      1.000000         1.000000     185.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# except_target = train.drop('ID', axis = 1)\n",
    "# except_target.hist(figsize = (12,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'TRAIN_00000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m,\u001b[39m20\u001b[39m), dpi \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m sns\u001b[39m.\u001b[39mheatmap(train\u001b[39m.\u001b[39;49mcorr(), annot \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, cmap \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1838\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[0;32m   1840\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[0;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'TRAIN_00000'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train = train.drop(['ID'], axis=1)\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (20,20), dpi = 100)\n",
    "sns.heatmap(train.corr(), annot = True, cmap = 'Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 독립변수, 종속변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['ID', 'critical_temp'], axis = 1)\n",
    "Y = train['critical_temp']\n",
    "\n",
    "X_test = test.drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델학습 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folds: 100%|██████████| 5/5 [15:55<00:00, 191.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMAE scores for each fold: [0.2519943557485278, 0.26020982878125093, 0.2589922873706145, 0.25759442123110915, 0.2478681896699405]\n",
      "Average NMAE: 0.2553318165602886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# 두 개의 모델 정의\n",
    "rf = RandomForestRegressor()\n",
    "gb = SVR()\n",
    "\n",
    "# 5-Fold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 각 fold의 모델로부터의 예측을 저장할 리스트와 NMAE 점수 리스트\n",
    "ensemble_predictions = []\n",
    "nmae_scores = []\n",
    "\n",
    "for train_idx, val_idx in tqdm(kf.split(X), total=5, desc=\"Processing folds\"):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = Y[train_idx], Y[val_idx]\n",
    "    \n",
    "    # 두 모델 모두 학습\n",
    "    rf.fit(X_train, y_train)\n",
    "    gb.fit(X_train, y_train)\n",
    "    \n",
    "    # 각 모델로부터 Validation set에 대한 예측을 평균내어 앙상블 예측 생성\n",
    "    ensemble_val_pred = (rf.predict(X_val) + gb.predict(X_val)) / 2\n",
    "    \n",
    "    # NMAE (Normalized MAE) 계산 후 저장\n",
    "    mae = mean_absolute_error(y_val, ensemble_val_pred)\n",
    "    nmae = mae / np.mean(abs(y_val))\n",
    "    nmae_scores.append(nmae)\n",
    "    \n",
    "    # test 데이터셋에 대한 예측 수행 후 저장\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    gb_pred = gb.predict(X_test)\n",
    "    \n",
    "    # 두 모델의 예측을 평균내어 앙상블 예측 생성\n",
    "    ensemble_pred = (rf_pred + gb_pred) / 2\n",
    "    ensemble_predictions.append(ensemble_pred)\n",
    "\n",
    "# K-fold 모든 예측의 평균을 계산하여 최종 앙상블 예측 생성\n",
    "final_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "# 각 fold에서의 NMAE와 전체 평균 NMAE 출력\n",
    "print(\"NMAE scores for each fold:\", nmae_scores)\n",
    "print(\"Average NMAE:\", np.mean(nmae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folds:   0%|          | 0/5 [10:50:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m y_train, y_val \u001b[39m=\u001b[39m Y[train_idx], Y[val_idx]\n\u001b[0;32m     43\u001b[0m \u001b[39m# Random Forest 모델에 대한 그리드 서치 수행\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m grid_rf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     45\u001b[0m best_rf \u001b[39m=\u001b[39m grid_rf\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m     47\u001b[0m \u001b[39m# Gradient Boosting 모델에 대한 그리드 서치 수행\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 두 개의 모델 정의\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# 데이터 분할을 위한 K-Fold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 그리드 서치를 위한 파라미터 그리드 정의\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200,300,400,500,600],\n",
    "    'learning_rate': [0.01, 0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'max_depth': [3, 4, 5,8,10,12,15,18,21],\n",
    "    'min_samples_split': [2, 5, 10,13,16,19,22,25,28,31],\n",
    "    'min_samples_leaf': [1, 2, 4,6,8,10,12]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, scoring='neg_mean_absolute_error', cv=kf)\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, scoring='neg_mean_absolute_error', cv=kf)\n",
    "\n",
    "# 각 fold의 모델로부터의 예측을 저장할 리스트와 NMAE 점수 리스트 초기화\n",
    "ensemble_predictions = []\n",
    "nmae_scores = []\n",
    "\n",
    "# 각 fold 별로 모델 학습 및 예측 수행\n",
    "for train_idx, val_idx in tqdm(kf.split(X), total=5, desc=\"Processing folds\"):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = Y[train_idx], Y[val_idx]\n",
    "    \n",
    "    # Random Forest 모델에 대한 그리드 서치 수행\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    \n",
    "    # Gradient Boosting 모델에 대한 그리드 서치 수행\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "    best_gb = grid_gb.best_estimator_\n",
    "    \n",
    "    # 각 모델로부터 Validation set에 대한 예측 생성\n",
    "    rf_val_pred = best_rf.predict(X_val)\n",
    "    gb_val_pred = best_gb.predict(X_val)\n",
    "    \n",
    "    # 두 모델의 예측을 평균내어 앙상블 예측 생성\n",
    "    ensemble_val_pred = (rf_val_pred + gb_val_pred) / 2\n",
    "    \n",
    "    # NMAE (Normalized MAE) 계산 후 저장\n",
    "    nmae = mean_absolute_error(y_val, ensemble_val_pred) / np.mean(abs(y_val))\n",
    "    nmae_scores.append(nmae)\n",
    "    \n",
    "    # test 데이터셋에 대한 예측 수행\n",
    "    rf_test_pred = best_rf.predict(X_test)\n",
    "    gb_test_pred = best_gb.predict(X_test)\n",
    "    \n",
    "    # 두 모델의 예측을 평균내어 앙상블 예측 생성 및 저장\n",
    "    ensemble_test_pred = (rf_test_pred + gb_test_pred) / 2\n",
    "    ensemble_predictions.append(ensemble_test_pred)\n",
    "\n",
    "# K-fold 모든 예측의 평균을 계산하여 최종 앙상블 예측 생성\n",
    "final_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "# 각 fold에서의 NMAE와 전체 평균 NMAE 출력\n",
    "print(\"NMAE scores for each fold:\", nmae_scores)\n",
    "print(\"Average NMAE:\", np.mean(nmae_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>2.883359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>4.187488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>12.677138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  critical_temp\n",
       "0  TEST_00000       2.883359\n",
       "1  TEST_00001       4.187488\n",
       "2  TEST_00002      12.677138"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['critical_temp'] = final_predictions\n",
    "submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('E:/초전도체/초전도체/models/baseline_submit_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
